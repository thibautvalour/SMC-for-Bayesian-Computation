{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "from init import init_Y\n",
    "from metrics import X_in_A, rho, eta, ESS, prop_alive_func\n",
    "from stats import sampling_params, random_walk_on_params, pi_n, X_update, metropolis_X_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 : initialisation\n",
    "alpha = 0.9\n",
    "N = 1000\n",
    "Nt = 500\n",
    "Y = init_Y()\n",
    "Xs = [[1]]*N\n",
    "epsilon_final = 0.00045\n",
    "epsilon_t = 1000\n",
    "espilon_list = [epsilon_t]\n",
    "random_walk_stds = (0.05, 0.05, 0.7)\n",
    "Ws = 1/N * np.ones(N)\n",
    "prop_alive = prop_alive_func(Ws)\n",
    "thetas = np.array([sampling_params() for _ in range(N)])\n",
    "\n",
    "for index, X in enumerate(Xs): # We do an updating so the Xs are not all the same at the beginning\n",
    "    phi, tau, xi = thetas[index]\n",
    "    X, phi, tau, xi= metropolis_X_theta(X, Y, phi, tau, xi,\n",
    "                                        epsilon_t, random_walk_stds)\n",
    "    thetas[index] = (phi, tau, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "while epsilon_t > epsilon_final:\n",
    "    print(f'Step 1 : t={t}') # Step 1 : sampling\n",
    "\n",
    "    new_weights = Ws\n",
    "    iteration = 0\n",
    "    while (prop_alive_func(new_weights) > alpha*prop_alive_func(Ws)) or (np.sum(new_weights) == 0):\n",
    "        new_weights = Ws * np.array([int(X_in_A(Y, X, epsilon_t)) for X in Xs])\n",
    "\n",
    "        amortization_factor = np.exp(-iteration/10)\n",
    "        if np.sum(new_weights) == 0: # epsilon_t is too small\n",
    "            epsilon_t *= 1 + 0.1 * amortization_factor\n",
    "        else: # epsilon_t is too big\n",
    "            epsilon_t *= 1 - 0.1 * amortization_factor\n",
    "        print(prop_alive_func(new_weights), prop_alive_func(Ws), epsilon_t)\n",
    "        iteration += 1\n",
    "\n",
    "\n",
    "\n",
    "        time.sleep(0.5)\n",
    "    Ws = new_weights\n",
    "    if epsilon_t < epsilon_final:\n",
    "        epsilon_t = epsilon_final\n",
    "    espilon_list.append(epsilon_t)\n",
    "\n",
    "    print('Step 2') # Step 2 : resampling\n",
    "    if ESS(Ws) < Nt:\n",
    "        indices = np.random.choice(range(N), size=N, replace=True, p=Ws)\n",
    "        Xs = [Xs[i] for i in indices]\n",
    "        thetas = [thetas[i] for i in indices]\n",
    "        Ws = 1/N * np.ones(N)\n",
    "        \n",
    "    print('Step 3') # Step 3 : random walk\n",
    "    for index, X in enumerate(Xs):\n",
    "        if Ws[index] > 0:\n",
    "            phi, tau, xi = thetas[index]\n",
    "            X, phi, tau, xi= metropolis_X_theta(X, Y, phi, tau, xi,\n",
    "                                                       epsilon_t, random_walk_stds)\n",
    "            thetas[index] = (phi, tau, xi)\n",
    "    t+=1\n",
    "    print(f'espilon_t = {epsilon_t}, epsilon_final = {epsilon_final}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6b9668d8a15f43186a70f0f81c0101d9fae62f7b2f887f04b88e4cf956a85de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
